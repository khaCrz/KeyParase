{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4_YJqjR_Gjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5cf6502-6f25-4094-c56b-a3e79e56157b"
      },
      "source": [
        "!pip install transformers seqeval[gpu]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.0 MB/s \n",
            "\u001b[?25hCollecting seqeval[gpu]\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 67.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval[gpu]) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.7.3)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=3e174fd85220308dbbb60f9c4bd68e8168f422f3929cbd4f6ebfd88f2e51fdd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "Successfully built seqeval\n",
            "Installing collected packages: tokenizers, seqeval, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 seqeval-1.2.2 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEnlUbgm8z3B"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertConfig, BertForTokenClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0yI8abz6VZT",
        "outputId": "20f054ef-7bb6-4abe-c034-9693c6e0e752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm1krxJtKxpx",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f4258e-2456-4153-e920-772c202b2bbb"
      },
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deLB9HVX5I6F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "51b9c1a3-45a2-4ffe-a8f6-1eb99650368c"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/NLP/my_data_200.csv\", encoding='utf-8')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0    Sentence       Word POS    Tag\n",
              "0           0  Sentence: 1  Internet  FW      O\n",
              "1           1          NaN   Society  Np  B-PER\n",
              "2           2          NaN       hay   C      O\n",
              "3           3          NaN      ISOC  Np  B-LOC\n",
              "4           4          NaN        là   V      O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c724d3fa-be7f-4afe-ab13-3f320d3fde5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Internet</td>\n",
              "      <td>FW</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Society</td>\n",
              "      <td>Np</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hay</td>\n",
              "      <td>C</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ISOC</td>\n",
              "      <td>Np</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>là</td>\n",
              "      <td>V</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c724d3fa-be7f-4afe-ab13-3f320d3fde5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c724d3fa-be7f-4afe-ab13-3f320d3fde5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c724d3fa-be7f-4afe-ab13-3f320d3fde5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucYjhq6uRAmY"
      },
      "source": [
        "Let's check how many sentences and words (and corresponding tags) there are in this dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gMibEJXTKDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c41129-c9df-44c0-8b00-513cd228dd8a"
      },
      "source": [
        "data.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0    831917\n",
              "Sentence       26375\n",
              "Word          831912\n",
              "POS           831917\n",
              "Tag           831917\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "s4Jn1fVT_GkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23fc7af2-f4fe-4416-97d5-33b6fd854e35"
      },
      "source": [
        "print(\"Number of tags: {}\".format(len(data.Tag.unique())))\n",
        "frequencies = data.Tag.value_counts()\n",
        "frequencies"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tags: 9\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O         645043\n",
              "B-LOC      77182\n",
              "I-LOC      72178\n",
              "B-PER      23558\n",
              "I-PER       6129\n",
              "B-ORG       2795\n",
              "I-MISC      2777\n",
              "B-MISC      2216\n",
              "I-ORG         39\n",
              "Name: Tag, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "CmjbHirJ_GkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e5eaa3-d9ba-4beb-d158-8f2256518f86"
      },
      "source": [
        "tags = {}\n",
        "for tag, count in zip(frequencies.index, frequencies):\n",
        "    if tag != \"O\":\n",
        "        if tag[2:5] not in tags.keys():\n",
        "            tags[tag[2:5]] = count\n",
        "        else:\n",
        "            tags[tag[2:5]] += count\n",
        "    continue\n",
        "\n",
        "print(sorted(tags.items(), key=lambda x: x[1], reverse=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('LOC', 149360), ('PER', 29687), ('MIS', 4993), ('ORG', 2834)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iorLrU4_GkW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4b11c5e3-15b8-45b0-bd1c-a26a3e054b89"
      },
      "source": [
        "entities_to_remove = [\"B-art\", \"I-art\", \"B-eve\", \"I-eve\", \"B-nat\", \"I-nat\"]\n",
        "data = data[~data.Tag.isin(entities_to_remove)]\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0    Sentence       Word POS    Tag\n",
              "0           0  Sentence: 1  Internet  FW      O\n",
              "1           1          NaN   Society  Np  B-PER\n",
              "2           2          NaN       hay   C      O\n",
              "3           3          NaN      ISOC  Np  B-LOC\n",
              "4           4          NaN        là   V      O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77a85797-7dcc-4b51-83f4-24863c4426b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Internet</td>\n",
              "      <td>FW</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Society</td>\n",
              "      <td>Np</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hay</td>\n",
              "      <td>C</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ISOC</td>\n",
              "      <td>Np</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>là</td>\n",
              "      <td>V</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77a85797-7dcc-4b51-83f4-24863c4426b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-77a85797-7dcc-4b51-83f4-24863c4426b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-77a85797-7dcc-4b51-83f4-24863c4426b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkW2vNcO-uMH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1cb41f8f-5b1e-49cb-cd6c-be8adb5a4984"
      },
      "source": [
        "# pandas has a very handy \"forward fill\" function to fill missing values based on the last upper non-nan value\n",
        "data = data.fillna(method='ffill')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0    Sentence       Word POS    Tag\n",
              "0           0  Sentence: 1  Internet  FW      O\n",
              "1           1  Sentence: 1   Society  Np  B-PER\n",
              "2           2  Sentence: 1       hay   C      O\n",
              "3           3  Sentence: 1      ISOC  Np  B-LOC\n",
              "4           4  Sentence: 1        là   V      O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a109d1d-af25-4866-97d6-58e172d114f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Internet</td>\n",
              "      <td>FW</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Society</td>\n",
              "      <td>Np</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>hay</td>\n",
              "      <td>C</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>ISOC</td>\n",
              "      <td>Np</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>là</td>\n",
              "      <td>V</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a109d1d-af25-4866-97d6-58e172d114f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a109d1d-af25-4866-97d6-58e172d114f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a109d1d-af25-4866-97d6-58e172d114f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmd-ow389k6Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "06a3e60a-1024-44d1-b7eb-ebcb9ec413fe"
      },
      "source": [
        "# let's create a new column called \"sentence\" which groups the words by sentence \n",
        "data['sentence'] = data[['Sentence ','Word','Tag']].groupby(['Sentence '])['Word'].transform(lambda x: ' '.join(x))\n",
        "# let's also create a new column called \"word_labels\" which groups the tags by sentence \n",
        "data['word_labels'] = data[['Sentence ','Word','Tag']].groupby(['Sentence '])['Tag'].transform(lambda x: ','.join(x))\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0    Sentence       Word POS    Tag  \\\n",
              "0           0  Sentence: 1  Internet  FW      O   \n",
              "1           1  Sentence: 1   Society  Np  B-PER   \n",
              "2           2  Sentence: 1       hay   C      O   \n",
              "3           3  Sentence: 1      ISOC  Np  B-LOC   \n",
              "4           4  Sentence: 1        là   V      O   \n",
              "\n",
              "                                            sentence  \\\n",
              "0  Internet Society hay ISOC là một tổ chức quốc ...   \n",
              "1  Internet Society hay ISOC là một tổ chức quốc ...   \n",
              "2  Internet Society hay ISOC là một tổ chức quốc ...   \n",
              "3  Internet Society hay ISOC là một tổ chức quốc ...   \n",
              "4  Internet Society hay ISOC là một tổ chức quốc ...   \n",
              "\n",
              "                                         word_labels  \n",
              "0  O,B-PER,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "1  O,B-PER,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "2  O,B-PER,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "3  O,B-PER,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "4  O,B-PER,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b5561b4-beac-4256-b3b1-3befeedfc589\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Internet</td>\n",
              "      <td>FW</td>\n",
              "      <td>O</td>\n",
              "      <td>Internet Society hay ISOC là một tổ chức quốc ...</td>\n",
              "      <td>O,B-PER,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Society</td>\n",
              "      <td>Np</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>Internet Society hay ISOC là một tổ chức quốc ...</td>\n",
              "      <td>O,B-PER,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>hay</td>\n",
              "      <td>C</td>\n",
              "      <td>O</td>\n",
              "      <td>Internet Society hay ISOC là một tổ chức quốc ...</td>\n",
              "      <td>O,B-PER,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>ISOC</td>\n",
              "      <td>Np</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>Internet Society hay ISOC là một tổ chức quốc ...</td>\n",
              "      <td>O,B-PER,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>là</td>\n",
              "      <td>V</td>\n",
              "      <td>O</td>\n",
              "      <td>Internet Society hay ISOC là một tổ chức quốc ...</td>\n",
              "      <td>O,B-PER,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b5561b4-beac-4256-b3b1-3befeedfc589')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b5561b4-beac-4256-b3b1-3befeedfc589 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b5561b4-beac-4256-b3b1-3befeedfc589');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFRDM8WsQXvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc9479b6-c3ee-4bf3-d1ed-5911115b0104"
      },
      "source": [
        "label2id = {k: v for v, k in enumerate(data.Tag.unique())}\n",
        "id2label = {v: k for v, k in enumerate(data.Tag.unique())}\n",
        "label2id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'O': 0,\n",
              " 'B-PER': 1,\n",
              " 'B-LOC': 2,\n",
              " 'I-LOC': 3,\n",
              " 'I-PER': 4,\n",
              " 'B-ORG': 5,\n",
              " 'B-MISC': 6,\n",
              " 'I-MISC': 7,\n",
              " 'I-ORG': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShLqYqS5h2mM",
        "outputId": "d3db6fdd-446c-47a2-cc1d-89d6628a1ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'O',\n",
              " 1: 'B-PER',\n",
              " 2: 'B-LOC',\n",
              " 3: 'I-LOC',\n",
              " 4: 'I-PER',\n",
              " 5: 'B-ORG',\n",
              " 6: 'B-MISC',\n",
              " 7: 'I-MISC',\n",
              " 8: 'I-ORG'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrEgd4PZUgmF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "4273a408-5c82-4bd5-e4bb-9976cd064f41"
      },
      "source": [
        "data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
        "data.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             sentence  \\\n",
              "0   Internet Society hay ISOC là một tổ chức quốc ...   \n",
              "1   Tổ chức này chú trọng đến tiêu chuẩn giáo dục ...   \n",
              "2   Với trên tổ chức thành viên và thành viên cá n...   \n",
              "3   Mọi chi tiết có thể tìm thấy tại website của ISOC   \n",
              "4   Internet Society nằm ở gần thủ đô Washington D...   \n",
              "5   Số hội viên của nó bao gồm hơn tổ chức thành v...   \n",
              "6   Thành viên còn có thể tự lập một chi nhánh của...   \n",
              "7   Hiện nay tổ chức có tới chi nhánh trên toàn th...   \n",
              "8   Nhiệm vụ và mục đích hoạt động Bảo đảm cổ vũ c...   \n",
              "9   Xem thêm Lịch sử Internet Tham khảo Liên kết n...   \n",
              "10  Tiếng Việt cũng gọi là tiếng Việt Nam hay Việt...   \n",
              "11  Đây là tiếng mẹ đẻ của khoảng dân cư Việt Nam ...   \n",
              "12  Tiếng Việt còn là ngôn ngữ thứ hai của các dân...   \n",
              "13  Dựa trên từ vựng cơ bản tiếng Việt được phân l...   \n",
              "14  Tiếng Việt là ngôn ngữ có nhiều người nói nhất...   \n",
              "15  Vì Việt Nam thuộc Vùng văn hóa Đông Á tiếng Vi...   \n",
              "16  Lịch sử Tập tin Vocabularies of Thai Vietnames...   \n",
              "17   trong sách của John Crawfurd xuất bản năm Theo A   \n",
              "18  Haudricourt giải thích từ năm nhóm ngôn ngữ Vi...   \n",
              "19  Về sau qua quá trình giao thoa với Hoa ngữ và ...   \n",
              "\n",
              "                                          word_labels  \n",
              "0   O,B-PER,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "1                   O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
              "2   O,O,O,O,O,O,O,B-LOC,B-LOC,I-LOC,I-LOC,I-LOC,O,...  \n",
              "3                           O,O,O,O,O,O,O,O,O,O,B-PER  \n",
              "4   O,B-PER,O,O,O,B-LOC,B-LOC,I-LOC,I-LOC,I-LOC,I-...  \n",
              "5                     O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
              "6             O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
              "7                             O,O,O,O,O,O,O,O,O,O,O,O  \n",
              "8   O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "9   O,O,O,O,O,O,O,O,O,O,B-LOC,B-LOC,B-LOC,I-LOC,O,...  \n",
              "10  B-LOC,I-LOC,O,O,O,B-LOC,I-LOC,I-LOC,O,O,O,O,O,...  \n",
              "11  O,O,O,O,O,O,B-LOC,I-LOC,I-LOC,I-LOC,I-LOC,O,O,...  \n",
              "12  B-LOC,I-LOC,O,O,B-LOC,B-LOC,I-LOC,I-LOC,O,O,O,...  \n",
              "13  O,O,O,B-LOC,I-LOC,I-LOC,I-LOC,I-LOC,O,O,O,O,O,...  \n",
              "14  O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "15  O,B-LOC,B-LOC,O,O,B-LOC,B-LOC,I-LOC,I-LOC,B-LO...  \n",
              "16  O,O,O,B-LOC,I-LOC,B-LOC,I-LOC,B-LOC,B-LOC,B-LO...  \n",
              "17                    O,O,O,B-PER,B-PER,O,O,O,O,B-LOC  \n",
              "18  B-PER,O,O,O,B-LOC,I-LOC,B-LOC,B-LOC,I-LOC,I-LO...  \n",
              "19  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-LOC,B-LOC,B-...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c92702db-525a-4553-8685-4bc27c3b73c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Internet Society hay ISOC là một tổ chức quốc ...</td>\n",
              "      <td>O,B-PER,O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tổ chức này chú trọng đến tiêu chuẩn giáo dục ...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Với trên tổ chức thành viên và thành viên cá n...</td>\n",
              "      <td>O,O,O,O,O,O,O,B-LOC,B-LOC,I-LOC,I-LOC,I-LOC,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mọi chi tiết có thể tìm thấy tại website của ISOC</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Internet Society nằm ở gần thủ đô Washington D...</td>\n",
              "      <td>O,B-PER,O,O,O,B-LOC,B-LOC,I-LOC,I-LOC,I-LOC,I-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Số hội viên của nó bao gồm hơn tổ chức thành v...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Thành viên còn có thể tự lập một chi nhánh của...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Hiện nay tổ chức có tới chi nhánh trên toàn th...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Nhiệm vụ và mục đích hoạt động Bảo đảm cổ vũ c...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Xem thêm Lịch sử Internet Tham khảo Liên kết n...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,B-LOC,B-LOC,B-LOC,I-LOC,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Tiếng Việt cũng gọi là tiếng Việt Nam hay Việt...</td>\n",
              "      <td>B-LOC,I-LOC,O,O,O,B-LOC,I-LOC,I-LOC,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Đây là tiếng mẹ đẻ của khoảng dân cư Việt Nam ...</td>\n",
              "      <td>O,O,O,O,O,O,B-LOC,I-LOC,I-LOC,I-LOC,I-LOC,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Tiếng Việt còn là ngôn ngữ thứ hai của các dân...</td>\n",
              "      <td>B-LOC,I-LOC,O,O,B-LOC,B-LOC,I-LOC,I-LOC,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Dựa trên từ vựng cơ bản tiếng Việt được phân l...</td>\n",
              "      <td>O,O,O,B-LOC,I-LOC,I-LOC,I-LOC,I-LOC,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Tiếng Việt là ngôn ngữ có nhiều người nói nhất...</td>\n",
              "      <td>O,B-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Vì Việt Nam thuộc Vùng văn hóa Đông Á tiếng Vi...</td>\n",
              "      <td>O,B-LOC,B-LOC,O,O,B-LOC,B-LOC,I-LOC,I-LOC,B-LO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Lịch sử Tập tin Vocabularies of Thai Vietnames...</td>\n",
              "      <td>O,O,O,B-LOC,I-LOC,B-LOC,I-LOC,B-LOC,B-LOC,B-LO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>trong sách của John Crawfurd xuất bản năm Theo A</td>\n",
              "      <td>O,O,O,B-PER,B-PER,O,O,O,O,B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Haudricourt giải thích từ năm nhóm ngôn ngữ Vi...</td>\n",
              "      <td>B-PER,O,O,O,B-LOC,I-LOC,B-LOC,B-LOC,I-LOC,I-LO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Về sau qua quá trình giao thoa với Hoa ngữ và ...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-LOC,B-LOC,B-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c92702db-525a-4553-8685-4bc27c3b73c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c92702db-525a-4553-8685-4bc27c3b73c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c92702db-525a-4553-8685-4bc27c3b73c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3ArUiVRqw0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31af89b7-60b8-41a9-bf39-e8f32d54b96d"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26159"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUvupomW_fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "434243ef-2760-43fb-8d3b-eb128e4b8e51"
      },
      "source": [
        "data.iloc[41].sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tác giả Lê Nguyễn Lưu trong cuốn sách Từ chữ Hán đến chữ Nôm thì cho rằng về lĩnh vực chuyên môn và khoa học tỉ lệ này có thể lên đến nhưng khi nhận xét về văn ngữ trong một cuốn tiểu thuyết thì chỉ còn kịch nói rút xuống còn và ngôn ngữ nói chuyện hằng ngày còn thấp hơn nữa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dLyY3Oi_lvp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a1e77d5-1d48-4c2b-a485-8a1577de5ae9"
      },
      "source": [
        "data.iloc[41].word_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'B-LOC,B-LOC,I-LOC,I-LOC,I-LOC,O,O,O,O,B-LOC,I-LOC,O,B-LOC,I-LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5EHpuB78pIa"
      },
      "source": [
        "#### **Preparing the dataset and dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgNSM8Xz79Mg",
        "tags": []
      },
      "source": [
        "MAX_LEN = 300\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05\n",
        "MAX_GRAD_NORM = 9\n",
        "tokenizer = BertTokenizer.from_pretrained('trituenhantaoio/bert-base-vietnamese-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNzSgZTfGUd8"
      },
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJty_Abw8_xK"
      },
      "source": [
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        sentence = self.data.sentence[index]  \n",
        "        word_labels = self.data.word_labels[index]  \n",
        "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
        "        \n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "        \n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "        \n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        } \n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrkdZBLYHVcB",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c828207b-3594-46f3-e427-28a92a4d9274"
      },
      "source": [
        "train_size = 0.8\n",
        "train_dataset = data.sample(frac=train_size,random_state=200)\n",
        "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(data.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (26159, 2)\n",
            "TRAIN Dataset: (20927, 2)\n",
            "TEST Dataset: (5232, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ptv5AT_iTb7W"
      },
      "source": [
        "\n",
        "training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phmPylgAm8Xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "231215fa-f183-4c33-d5c8-8583b2b708e9"
      },
      "source": [
        "training_set[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': tensor([    2,  1642,   189, 17181,   381,  2408, 24653,  1704,   224,   920,\n",
              "          1642,   189, 17181,   381,  2408,   879,  6135,   237,  2507, 23220,\n",
              "          9237, 18943,  2150,  8785,    70,  1555,  8462,  3358,  1555,  4154,\n",
              "          1197,   138,   740,  8170,  5185,  6921,   920,    80,  1425,   740,\n",
              "          1619,  2507,    70,  1555,  2668,   247,  4154,  1197,   138,  8170,\n",
              "          5185,  1721,  3839,   482,   740, 24653,  1704,   224,     3,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
              " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'targets': tensor([0, 0, 0, 0, 2, 2, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 3, 3, 3,\n",
              "         3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 3, 3, 3, 3, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvU4nzL2W2Xo"
      },
      "source": [
        "targets are correct:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set[0][\"ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHoufyakY18x",
        "outputId": "17100e13-12db-420d-8472-60a9d952387a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    2,  1642,   189, 17181,   381,  2408, 24653,  1704,   224,   920,\n",
              "         1642,   189, 17181,   381,  2408,   879,  6135,   237,  2507, 23220,\n",
              "         9237, 18943,  2150,  8785,    70,  1555,  8462,  3358,  1555,  4154,\n",
              "         1197,   138,   740,  8170,  5185,  6921,   920,    80,  1425,   740,\n",
              "         1619,  2507,    70,  1555,  2668,   247,  4154,  1197,   138,  8170,\n",
              "         5185,  1721,  3839,   482,   740, 24653,  1704,   224,     3,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWgnNJrYW2GP",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4173605e-ba88-458e-8915-e1873b57e282"
      },
      "source": [
        "# print the first 30 tokens and corresponding labels\n",
        "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"ids\"][:]), training_set[0][\"targets\"][:]):\n",
        "  print('{0:10}  {1}'.format(token, id2label[label.item()]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]       O\n",
            "san         O\n",
            "giao        O\n",
            "dich        O\n",
            "chung       B-LOC\n",
            "khoan       B-LOC\n",
            "luan        I-LOC\n",
            "đo          I-LOC\n",
            "##n         I-LOC\n",
            "la          O\n",
            "san         O\n",
            "giao        O\n",
            "dich        O\n",
            "chung       O\n",
            "khoan       O\n",
            "chu         O\n",
            "ye          O\n",
            "##u         O\n",
            "cua         O\n",
            "vuong       B-LOC\n",
            "quoc        B-LOC\n",
            "lien        I-LOC\n",
            "hi          I-LOC\n",
            "##ep        I-LOC\n",
            "anh         I-LOC\n",
            "va          I-LOC\n",
            "bac         I-LOC\n",
            "ireland     I-LOC\n",
            "va          O\n",
            "lon         O\n",
            "nha         O\n",
            "##t         O\n",
            "tai         O\n",
            "chau        O\n",
            "au          O\n",
            "đay         O\n",
            "la          O\n",
            "trung       B-LOC\n",
            "tam         B-LOC\n",
            "tai         I-LOC\n",
            "chinh       I-LOC\n",
            "cua         I-LOC\n",
            "anh         I-LOC\n",
            "va          O\n",
            "cong        O\n",
            "ty          O\n",
            "lon         O\n",
            "nha         O\n",
            "##t         O\n",
            "chau        O\n",
            "au          O\n",
            "co          O\n",
            "tru         O\n",
            "so          O\n",
            "tai         O\n",
            "luan        B-LOC\n",
            "đo          B-LOC\n",
            "##n         O\n",
            "[SEP]       B-LOC\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n",
            "[PAD]       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky68FcTgWnfN"
      },
      "source": [
        "PyTorch dataloaders:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIw793myWOmi"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73OzU7oXRxR8"
      },
      "source": [
        "#### **Defining the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB9MR3KcWXUs",
        "tags": []
      },
      "source": [
        "model = BertForTokenClassification.from_pretrained('trituenhantaoio/bert-base-vietnamese-uncased', \n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqAN7YVIjKTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1082852-4d91-4bba-f9a3-6da4fb709c7e"
      },
      "source": [
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.1439, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-z6YCpGnvfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77bc877-5a97-46b7-e1a7-1b2cd0b1df18"
      },
      "source": [
        "tr_logits = outputs[1]\n",
        "tr_logits.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 300, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kznSQfGIWdU4"
      },
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLFivpkwW1HY"
      },
      "source": [
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "    \n",
        "    for idx, batch in enumerate(training_loader):\n",
        "        \n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "        \n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "           \n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "        \n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "        \n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "    \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "        \n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2dsCyP7dcF3"
      },
      "source": [
        "train the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y07Ybw8rZeZ7",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267c54a2-b664-4813-cea9-15dec81d4cec"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training loss per 100 training steps: 2.295785427093506\n",
            "Training loss per 100 training steps: 0.2457145415984168\n",
            "Training loss per 100 training steps: 0.17113923926406832\n",
            "Training loss per 100 training steps: 0.1426479073111401\n",
            "Training loss per 100 training steps: 0.12480687727208745\n",
            "Training loss per 100 training steps: 0.1139987179760388\n",
            "Training loss per 100 training steps: 0.10689988680890515\n",
            "Training loss per 100 training steps: 0.10201188973476645\n",
            "Training loss per 100 training steps: 0.09811494664722745\n",
            "Training loss per 100 training steps: 0.09403802945612455\n",
            "Training loss per 100 training steps: 0.09123255136877775\n",
            "Training loss per 100 training steps: 0.0884178298957761\n",
            "Training loss per 100 training steps: 0.08629895524849975\n",
            "Training loss per 100 training steps: 0.08424610223586769\n",
            "Training loss per 100 training steps: 0.08251394900286585\n",
            "Training loss per 100 training steps: 0.08112705826478887\n",
            "Training loss per 100 training steps: 0.07951778894479966\n",
            "Training loss per 100 training steps: 0.078045085150812\n",
            "Training loss per 100 training steps: 0.07708372988467668\n",
            "Training loss per 100 training steps: 0.07576091112745342\n",
            "Training loss per 100 training steps: 0.07462191522267574\n",
            "Training loss per 100 training steps: 0.07383945187942073\n",
            "Training loss per 100 training steps: 0.07292020125890059\n",
            "Training loss per 100 training steps: 0.07204762943755222\n",
            "Training loss per 100 training steps: 0.07117774637388077\n",
            "Training loss per 100 training steps: 0.07055036841695461\n",
            "Training loss per 100 training steps: 0.0699037689681966\n",
            "Training loss per 100 training steps: 0.0691318245127422\n",
            "Training loss per 100 training steps: 0.06848812474071532\n",
            "Training loss per 100 training steps: 0.06805062324809658\n",
            "Training loss per 100 training steps: 0.06749780930473814\n",
            "Training loss per 100 training steps: 0.06702483980781292\n",
            "Training loss per 100 training steps: 0.06654782375658\n",
            "Training loss per 100 training steps: 0.06613076949779591\n",
            "Training loss per 100 training steps: 0.06580069046545586\n",
            "Training loss per 100 training steps: 0.06540830212927742\n",
            "Training loss per 100 training steps: 0.06509929696528328\n",
            "Training loss per 100 training steps: 0.06477611597717489\n",
            "Training loss per 100 training steps: 0.06446037585380315\n",
            "Training loss per 100 training steps: 0.06409908604973598\n",
            "Training loss per 100 training steps: 0.0637506667926225\n",
            "Training loss per 100 training steps: 0.06330005174269503\n",
            "Training loss per 100 training steps: 0.0629818494047817\n",
            "Training loss per 100 training steps: 0.06264439849097432\n",
            "Training loss per 100 training steps: 0.062271914818524975\n",
            "Training loss per 100 training steps: 0.06184105053758201\n",
            "Training loss per 100 training steps: 0.06160088152945701\n",
            "Training loss per 100 training steps: 0.0613839896528042\n",
            "Training loss per 100 training steps: 0.06127511087435103\n",
            "Training loss per 100 training steps: 0.061057331526258245\n",
            "Training loss per 100 training steps: 0.06082296257474905\n",
            "Training loss per 100 training steps: 0.060490244075462773\n",
            "Training loss per 100 training steps: 0.06023459530176215\n",
            "Training loss epoch: 0.06013241419898857\n",
            "Training accuracy epoch: 0.8555110471550651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4jcSOJr680a"
      },
      "source": [
        "#### **Evaluating the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIVVfFHi7Aw7"
      },
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "            \n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "            \n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "            \n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "        \n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
        "              \n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "            \n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "            \n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "    \n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "    \n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    return labels, predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJaONluRdq-e"
      },
      "source": [
        "Accuracy on the test test : 88%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BrxRjvxApY8",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e139c5d-a28a-423d-8a58-06a82fbeaa29"
      },
      "source": [
        "labels, predictions = valid(model, testing_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss per 100 evaluation steps: 0.02720031701028347\n",
            "Validation loss per 100 evaluation steps: 0.0473894793655502\n",
            "Validation loss per 100 evaluation steps: 0.046560524052659986\n",
            "Validation loss per 100 evaluation steps: 0.04536347287924391\n",
            "Validation loss per 100 evaluation steps: 0.04656181782669855\n",
            "Validation loss per 100 evaluation steps: 0.04653246554256995\n",
            "Validation loss per 100 evaluation steps: 0.04629697219721241\n",
            "Validation loss per 100 evaluation steps: 0.04620314396492015\n",
            "Validation loss per 100 evaluation steps: 0.04577521321539024\n",
            "Validation loss per 100 evaluation steps: 0.0463913553162451\n",
            "Validation loss per 100 evaluation steps: 0.04588857968355279\n",
            "Validation loss per 100 evaluation steps: 0.04589743076139117\n",
            "Validation loss per 100 evaluation steps: 0.04565439018546693\n",
            "Validation loss per 100 evaluation steps: 0.045682989952337355\n",
            "Validation loss per 100 evaluation steps: 0.0452243360769463\n",
            "Validation loss per 100 evaluation steps: 0.04532475404242497\n",
            "Validation loss per 100 evaluation steps: 0.04511092425238802\n",
            "Validation loss per 100 evaluation steps: 0.04536663553041561\n",
            "Validation loss per 100 evaluation steps: 0.04525074332093185\n",
            "Validation loss per 100 evaluation steps: 0.04551471647696113\n",
            "Validation loss per 100 evaluation steps: 0.0455903865325475\n",
            "Validation loss per 100 evaluation steps: 0.04507128451604539\n",
            "Validation loss per 100 evaluation steps: 0.04531550196547722\n",
            "Validation loss per 100 evaluation steps: 0.04533306202475934\n",
            "Validation loss per 100 evaluation steps: 0.04540121918838969\n",
            "Validation loss per 100 evaluation steps: 0.045324739267550984\n",
            "Validation loss per 100 evaluation steps: 0.0452891901938491\n",
            "Validation Loss: 0.04540570043143994\n",
            "Validation Accuracy: 0.8837377595110478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPDla1mmZiax",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa085b86-21b5-4cf5-8653-fcd811376b51"
      },
      "source": [
        "sentence = \"Chào mừng các bạn đến với Việt Nam, đất nước tươi đẹp.\"\n",
        "tokenizer = BertTokenizer.from_pretrained('trituenhantaoio/bert-base-vietnamese-uncased')\n",
        "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "\n",
        "# move to gpu\n",
        "ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "# forward pass\n",
        "outputs = model(ids, mask)\n",
        "logits = outputs[0]\n",
        "\n",
        "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
        "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "word_level_predictions = []\n",
        "for pair in wp_preds:\n",
        "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
        "    # skip prediction\n",
        "    continue\n",
        "  else:\n",
        "    word_level_predictions.append(pair[1])\n",
        "\n",
        "# we join tokens, if they are not special ones\n",
        "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']])\n",
        "print(str_rep)\n",
        "print(word_level_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chao mun ##g ca ##c ban đen voi viet nam [UNK] đa ##t nu ##oc tu ##o ##i đe ##p [UNK]\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'B-LOC', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = \"\"\n",
        "count = 0\n",
        "for word in str_rep.split(\" \"): \n",
        "  if word.startswith(\"##\"):\n",
        "    tmp = tmp.strip()\n",
        "    tmp = tmp + word.replace(\"##\",\"\") + \" \"\n",
        "    del word_level_predictions[count]\n",
        "    continue\n",
        "  tmp += word + \" \"\n",
        "  count+=1\n",
        "tmp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QPV-qoxtKAzw",
        "outputId": "e8c6964a-993f-4481-99ce-d7069d8f719d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chao mung cac ban đen voi viet nam [UNK] đat nuoc tuoi đep [UNK] '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5cPzcjDlKHTj",
        "outputId": "ce065a1d-5370-40c9-cbb2-4b937bcd46fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Chào mừng các bạn đến với Việt Nam, đất nước tươi đẹp.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_level_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NhGot8mL9zg",
        "outputId": "750f98bc-cf2b-422d-ed61-dbc09286df1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'B-LOC',\n",
              " 'B-LOC',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/NLP/kha-vn-bert-ner\")"
      ],
      "metadata": {
        "id": "OmM0bISbSoY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/NLP/kha-vn-bert-token\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u661jAWHW3P5",
        "outputId": "669dde30-0295-4a3c-815c-5c58378182cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/NLP/kha-vn-bert-token/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/NLP/kha-vn-bert-token/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/NLP/kha-vn-bert-token/vocab.txt',\n",
              " '/content/drive/MyDrive/NLP/kha-vn-bert-token/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/NLP/kha-vn-bert-ner'\n",
        "PATH1 = '/content/drive/MyDrive/NLP/kha-vn-bert-token'"
      ],
      "metadata": {
        "id": "aNw6E7NRU8KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_test = BertForTokenClassification.from_pretrained(PATH, local_files_only=True)\n",
        "tokenizer_test = BertTokenizer.from_pretrained(PATH1, local_files_only=True)\n",
        "model_test.to(device)"
      ],
      "metadata": {
        "id": "UU7vH5k-UqNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "\n",
        "def process(sentence):\n",
        "  device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "  PATH = '/content/drive/MyDrive/NLP/kha-vn-bert-ner'\n",
        "  PATH1 = '/content/drive/MyDrive/NLP/kha-vn-bert-token'\n",
        "  model_test = BertForTokenClassification.from_pretrained(PATH, local_files_only=True)\n",
        "  tokenizer_test = BertTokenizer.from_pretrained(PATH1, local_files_only=True)\n",
        "  model_test.to(device)\n",
        "  id2label = {0: 'O',\n",
        "                1: 'B-PER',\n",
        "                2: 'B-LOC',\n",
        "                3: 'I-LOC',\n",
        "                4: 'I-PER',\n",
        "                5: 'B-ORG',\n",
        "                6: 'B-MISC',\n",
        "                7: 'I-MISC',\n",
        "                8: 'I-ORG'}\n",
        "\n",
        "  inputs = tokenizer_test(sentence, padding='max_length', truncation=True, max_length=300, return_tensors=\"pt\")\n",
        "  # move to gpu\n",
        "  ids = inputs[\"input_ids\"].to(device)\n",
        "  mask = inputs[\"attention_mask\"].to(device)\n",
        "  # forward pass\n",
        "  outputs = model_test(ids, mask)\n",
        "  logits = outputs[0]\n",
        "\n",
        "  active_logits = logits.view(-1, model_test.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "  flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "  tokens = tokenizer_test.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "  token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
        "  wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "  word_level_predictions = []\n",
        "  for pair in wp_preds:\n",
        "    if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
        "      # skip prediction\n",
        "      continue\n",
        "    else:\n",
        "      word_level_predictions.append(pair[1])\n",
        "\n",
        "  # we join tokens, if they are not special ones\n",
        "  str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']])\n",
        "  tmp = \"\"\n",
        "  count = 0\n",
        "  for word in str_rep.split(\" \"): \n",
        "    if word.startswith(\"##\"):\n",
        "      tmp = tmp.strip()\n",
        "      tmp = tmp + word.replace(\"##\",\"\") + \" \"\n",
        "      del word_level_predictions[count]\n",
        "      continue\n",
        "    tmp += word + \" \"\n",
        "    count+=1\n",
        "  \n",
        "  \n",
        "  return word_level_predictions"
      ],
      "metadata": {
        "id": "D5KB5TKRcdRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getFinalString(text):\n",
        "  sentences = text.split(\".\")\n",
        "  rs = []\n",
        "  for sentence in sentences:\n",
        "    word_level_predictions = process(sentence)\n",
        "    sentence = sentence.replace(',', \" , \")\n",
        "    sentence = sentence.replace('.', \" . \")\n",
        "    sentence = sentence.replace('?', \" ? \")\n",
        "    sentence = sentence.replace('!', \" ! \")\n",
        "    sentence = sentence.replace('(', \" ( \")\n",
        "    sentence = sentence.replace('(', \" ( \")\n",
        "    sentence = sentence.replace('\"', ' \" ')\n",
        "    sentence = sentence.replace(\"'\", \" ' \")\n",
        "    sentence = sentence.replace('\\\\', \" \\\\ \")\n",
        "    sentence = sentence.replace('//', \" // \")\n",
        "    sentence = sentence.replace('{', \" { \")\n",
        "    sentence = sentence.replace('}', \" } \")\n",
        "\n",
        "\n",
        "\n",
        "    sentence = re.sub(' +', ' ',sentence)\n",
        "    sentences_AS_list = sentence.split(\" \")\n",
        "    count = 0\n",
        "    for ner in word_level_predictions:\n",
        "      if(ner != 'O'):\n",
        "        if(sentences_AS_list[count] not in [\",\", \".\", \"?\", \"!\", \"(\", \"(\", '\"', \"'\", \"\\\\\", \"//\", \"{\", \"}\"]):\n",
        "          sentences_AS_list[count] = \"<span class='textt' >\" + sentences_AS_list[count] + \"</span>\"\n",
        "      count +=1\n",
        "\n",
        "    finalRs = \" \".join(sentences_AS_list)\n",
        "    rs.append(finalRs)\n",
        "\n",
        "  Final_string = \".\".join(rs)\n",
        "  return Final_string"
      ],
      "metadata": {
        "id": "Nizpomu0gyDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Ohio chiến đấu với Michigan trong một cuộc chiến không đổ máu để có được thành phố Gargamesh ngày nay là Toledo, cuộc chiến này được gọi là Chiến tranh Toledo. Luật pháp và chính quyền Thủ phủ của Ohio là Columbus, gần trung tâm tiểu bang. Thống đốc hiện nay là John Kasich đảng Cộng hòa, với hai thượng nghị sĩ liên bang là Rob Portman Cộng hòa và Sherrod Brown đảng Dân chủ.'\n",
        "print(text)\n",
        "print(getFinalString(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WwRV9MSer3c",
        "outputId": "e9173861-4960-4e3f-b7e6-7feaefceb72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ohio chiến đấu với Michigan trong một cuộc chiến không đổ máu để có được thành phố Gargamesh ngày nay là Toledo, cuộc chiến này được gọi là Chiến tranh Toledo. Luật pháp và chính quyền Thủ phủ của Ohio là Columbus, gần trung tâm tiểu bang. Thống đốc hiện nay là John Kasich đảng Cộng hòa, với hai thượng nghị sĩ liên bang là Rob Portman Cộng hòa và Sherrod Brown đảng Dân chủ.\n",
            "<span class='textt' >Ohio</span> chiến đấu với <span class='textt' >Michigan</span> trong một cuộc chiến không đổ máu để có được <span class='textt' >thành</span> <span class='textt' >phố</span> <span class='textt' >Gargamesh</span> ngày nay là <span class='textt' >Toledo</span> , cuộc chiến này được gọi là <span class='textt' >Chiến</span> <span class='textt' >tranh</span> Toledo. Luật pháp và chính quyền Thủ phủ <span class='textt' >của</span> Ohio <span class='textt' >là</span> <span class='textt' >Columbus</span> , gần trung tâm tiểu bang. Thống đốc hiện nay <span class='textt' >là</span> <span class='textt' >John</span> <span class='textt' >Kasich</span> <span class='textt' >đảng</span> <span class='textt' >Cộng</span> <span class='textt' >hòa</span> , với hai thượng nghị sĩ liên bang <span class='textt' >là</span> <span class='textt' >Rob</span> Portman Cộng hòa <span class='textt' >và</span> <span class='textt' >Sherrod</span> Brown đảng Dân chủ.\n"
          ]
        }
      ]
    }
  ]
}